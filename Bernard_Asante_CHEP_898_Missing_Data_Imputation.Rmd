---
title: "Bernard_Asante_Missing_Data_Imputation"
author: "Bernard Asante"
date: "2025-02-01"
output:
  html_document:
    toc: true
    toc_float: true 
    toc_depth: 3
---

# **Loading libraries** 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(visdat)
library(naniar)
library(mice)
library(VIM)
library(cowplot)
```

# **Reading the dataset**

```{r, warning=FALSE}
path = "T:\\Desktop\\USASK\\Year One\\WINTER\\Data Science\\Data\\can_path_data.csv"

data <- read_csv(path)

#data %>% 
  #glimpse()  # Output is too long. 
```

Loading the entire can_path_student_dataset. This dataset has 440 variables(columns)  and 42287 observations(rows)

## Broad overview of missing data in dataset

```{r}
miss_var_summary(data) #The function miss_var_summary(data) from the naniar package summarizes missing data by variable. It returns a table showing the number and percentage of missing values for each column in the dataset. This helps identify which variables are most affected by missingness.
```

It can be observed some variables has more than 99 % missing values, at least from the first 10 rows. These variables are probably missing not at random(MNAR). For efficiency seek, I have decided to retain only variables with less that 20% missing values. 

## Missing data overview

```{r}
data_pct <- data %>%
          select(where(~sum(is.na(.x))/length(.x) < 0.20))  #This code filters the dataset data to retain only variables with less than 20% missing values.  
missing_table <- miss_var_summary(data_pct) #It then generates a summary table of missing values for the filtered dataset using miss_var_summary().

missing_table # missing_table is the variable showing how much missing data remains in each retained variable.


```

The 'missing_table' displayed above shows the percentage of missing data in the dataset after selecting variables with less that 20% missing data. The dataset with variables containing missing data less that 20% has been named "data_pct". Further processes will be performed on this data_pct instead of the entire dataset(data) 

```{r}
# Selecting 7 columns randomly from the dataset due to high computation power required for the entire dataset
health_data <- data %>% 
  
  select(ID,HS_GEN_HEALTH,NUT_VEG_QTY, NUT_FRUITS_QTY,PA_TOTAL_SHORT,DIS_ASTHMA_EVER,DIS_DIAB_EVER)

write.csv(health_data, "health_data.csv",row.names = FALSE)
```

This step is to further reduced the columns in the dataset to increase efficiency. Eleven(8) columns were selected from the data_pct(containing variables of less than 20% missing data). The output was saved as a new comma separated value(csv) file named "health_data.csv"

# **Sliced dataset[health_data]**

```{r}

health_data <- read_csv("health_data.csv")

health_data %>% 
  glimpse()   #The glimpse() function from the dplyr package provides a quick, structured overview of the health_data dataset. It shows the number of rows and columns, as well as the type and a preview of values in each column. This helps understand the structure and content of the dataset at a glance.

```

This is to give an overview of the new dataset (health_data.csv) displaying number of row (41187) and columns(7)


```{r}
health_data  %>% 
  head()  # Displaying the first 6 rows of the dataet 

health_data %>% 
  tail()  # Displaying the first 6 rows of the dataet 
```

```{r}
health_data %>% 
  summary() # The summary() function provides basic descriptive statistics for each variable in the health_data dataset. For numeric variables, it returns the minimum, 1st quartile, median, mean, 3rd quartile, and maximum values, along with the count of missing values (NA's). This offers a statistical snapshot of the datasetâ€™s distribution and data quality.
```

It can be observed that each variable has a missing data (NA's). This will be explained further in the next code

# **Missing Data Exploration**

```{r}
missing_columns <- health_data %>% 
  summarise_all(~sum(is.na(.))) # This code calculates the total number of missing values in each column of the health_data dataset. It uses summarise_all() with a function that counts NAs, returning a one-row summary where each column shows its respective missing count. The result is stored in missing_columns.
  

missing_columns

```
Now that I know  the missing values for each columns, I want to visualize them on a simple bar graph to see the order frequency of missing values for each column

## Visualization of missing data per columns 

```{r}
missing_columns_long <- missing_columns %>% 
  pivot_longer(cols = HS_GEN_HEALTH:DIS_DIAB_EVER, names_to = "columns", values_to = "counts") #This code reshapes the missing_columns summary into a long format using pivot_longer(), converting each column name and its missing value count into row entries. 

missing_columns_long     #The new dataframe missing_columns_long contains two columns: columns (variable names) and counts (number of missing values). This format is ideal for plotting
```

Here we see columns and counts(which represents the number of missing values in each variable)

```{r}
missing_plot <- missing_columns_long %>% 
  ggplot(aes(x = reorder(columns,counts), y = counts))+
  geom_segment(aes(x = reorder(columns,counts), yend = counts, xend = reorder(columns,counts), y =0))+
  geom_point(size = 4, colour = "#a13")+
  coord_flip()+
  labs(title = "Bar Graph of missing data in the dataset by columns", x = "Column_names")  # This code uses ggplot2 to create a horizontal bar plot showing the number of missing values per column in the dataset. It uses geom_segment() to draw the bars and geom_point() to emphasize each missing count. The columns are reordered by the number of missing values for better readability, and coord_flip() is used to display the bars horizontally.
  
missing_plot
```

From the graph, it can be seen that PA-TOTAL_SHORT has the highest missing data around 7000 where as HS_GEN_HEALTH has the least values less that 1000. The next step is to calculate for the percentage of missing data in each column usinng the miss_var_summary

## Percentage of the missing data 

```{r}
missing_data <- miss_var_summary(health_data) # This code uses miss_var_summary() to generate a summary of missing values for each variable in health_data, including both count and percentage of missing values. 

missing_data %>% 
  head(5) # The head(5) function then displays the top 5 variables with the highest missing value counts. 

```
I know Physical activity variable has the highest missing values of 16.4% this is evident from the bar graph above.

For other variables, the percentage of missing data is rarely a problem , Nut_veg_qty(6.19%), nut_fruits_qty(5.89%), Dis_asthma_Ever(2.98%) and Hs_Gen_health(1.63%). This is likely to make the data Missing Completely at Random(MCAR). However, it is hard to say for Pa_total_short which has a missing data 0f 16.4%, probably Missing at Random(MAR). These are mere assumptions and need to be analyzed further.

The visdat package was used to make some visualization to better understand the pattern of missing data in the dataset.


# **Visdat** 

## vis_dat()

```{r}
data_col_type <- vis_dat(health_data)  # The vis_dat(health_data) function from the visdat package creates a visualization showing the data type and missingness for each variable in the dataset. Each cell in the plot represents a data value, color-coded by type ( numeric, character, missing as seen in the plot). 

data_col_type # The output data_col_type is a ggplot object displaying this structure.
```
The gray color represents missing values in the dataset. It can be seen that ID has no missing values. Few missing values was seen with some variables which corresponds to the percentages above and the bar graph. we can see a lot of missing data in the Pa_total_short column.

## Vis_miss()

```{r}
vis_miss(health_data) # This code use the vis_miss() from the visdt package to display the percentage of missing data in each variable. 
```
This is to display only the missing values. The mising percentage can be seen against the names of each variable on the graph. This is same to the one observed using miss_var_summary from naniar package. 


## vis_cor()

```{r}
health_data_numeric <- health_data %>% 
  select(where(is.numeric)) # Selecting only numeric variables becuase the  vis_cor() function works on only numerical variables

vis_cor(health_data_numeric) # The function computes pairwise correlations and produces a heatmap that visually represents the strength and direction of relationships between numeric variables. Correlation values range from -1 (perfect negative) to +1 (perfect positive) with colour bar explaining the degree of correlation.
```
This heatmap is to display the correlation between the numeric variables in the dataset. There were moderate correlation observed between some of the variables; veg quantity and fruits quantity. similar observation is seen between diabetes ever and asthma ever. From theory, missing data in strongly correlated variables can be imputed using values from the other( except MNAR). But in this analysis, my interest is with Physical activity total which has mild correlation with the nutritional and diseases variables and  mild - moderate correlation with hs_gen_health.
## gg_miss_upset

```{r}
gg_miss_upset(health_data)  # The gg_miss_upset(health_data) function from the naniar package creates an UpSet plot that visualizes combinations of missing values across multiple variables. It shows how many observations have missing data in specific columns and in what combinations. This is especially useful when dealing with overlapping missingness in multiple variables.
```
From the gg-miss_upset plot above, we can observe a connection between missing data points in physical activity and the nutritional(NUT) variables, Physical activity NA is connected to all the variables at the intersection size of 334. 

I want to run further test to assess if the missingness in PA_TOTAL_SHORT is dependent on observed values in the other variables. 

# **Determining the type of missingness**

## Little MCAR test from naniar

```{r}
mcar_test(health_data) # The mcar_test(health_data) function from the naniar package performs Littleâ€™s MCAR (Missing Completely At Random) test on the dataset. It statistically tests whether the missing data pattern is completely random or not. The output includes a chi-square statistic, degrees of freedom, and a p-value.

```

The mcar test has the null hypothesis: The missing data is completerly at random(MCAR). Alternative hypothesis states that, missing data is not completely at random that is, it can be MAR or MNAR. 

The test had a pvalue less than 0.001. This is a strong evidence to reject the null hypothesis and conclude that the data is not missing completely at random. 

I want to see if missingness in pa_total  is MAR or MNAR using logistic regression to see how the various variables predicts the "NA" variables in pa_total_short. Logistic regression is used here because the missing data "NA" is not continuous but rather "TRUE" or "FALSE" as can be seen in _missing_pa_total_. 

## Logistic Regression Model

```{r}

missing_Pa_total <- is.na(health_data$PA_TOTAL_SHORT) %>% 
  head() #This code  is to give a logical output(TRUE or FAlSe) is there is missing value in PA_TOTAL_SHORT

print(missing_Pa_total)  # This displays the columns values as logical; TRUE and FALSE making binomial logistic regression appropriate

glm(is.na(PA_TOTAL_SHORT) ~ HS_GEN_HEALTH + NUT_FRUITS_QTY + DIS_ASTHMA_EVER + DIS_DIAB_EVER, 
    data = health_data, 
    family = binomial) %>% 
  summary()   # This code fits a binomial logistic regression model to predict whether the variable PA_TOTAL_SHORT is missing (TRUE) or not (FALSE). The predictors used are HS_GEN_HEALTH, NUT_FRUITS_QTY, DIS_ASTHMA_EVER, and DIS_DIAB_EVER. The model estimates the likelihood of missingness in PA_TOTAL_SHORT based on these other health-related variables.


```
It can be observed that all the variables has a pvalue < 0.001 indicating they are significant predictors of the missingness in the pa_total_short variable. Again this is an assumption from the model and can not be proven with high certainty

## Geom_miss_plot

```{r}
scatter_plot_miss <- ggplot(health_data, aes(x = NUT_FRUITS_QTY, y = PA_TOTAL_SHORT)) + 
                  geom_miss_point(alpha = 0.2) +
                  labs(x = "Fruits", y = "Physical Activity")
plot(scatter_plot_miss)  # This code creates a scatter plot using ggplot2 with geom_miss_point() from the naniar package, which plots data points while also highlighting missing values. The x-axis represents NUT_FRUITS_QTY and the y-axis PA_TOTAL_SHORT, with semi-transparent (alpha = 0.2) points. Missing values in either variable are marked distinctly with default "orange" colour.
```
It can be observed that missing decreases as fruit intake  increases above 8. A lot of missing data was also between 0 to 5000 minutes of exercise, however, missingness reduces above 5000 minutes upwards.



# **Shadow matrix**

```{r}
data_shadow <- health_data %>% 
  bind_shadow()  # The bind_shadow() function from the naniar package appends shadow columns to the original health_data dataset. For every original variable, it creates a new column with the _NA suffix, indicating whether each value is missing (NA) or not (!NA). The result, data_shadow, enables tracking and modeling of missingness directly.

data_shadow %>% 
  head() # This displays the first 6 rows of the data_shadow variable
```

The data shadow add an indicator matrix to the dataset to display is a value is missing(NA) or not missing(!NA)

# **Data Imputation**


## Summarizing missing data

```{r}

summary(health_data$PA_TOTAL_SHORT) # The  line  of code provides a five-number summary and counts of missing values in PA_TOTAL_SHORT. 

health_data %>% summarise(
  n_distinct = n_distinct(PA_TOTAL_SHORT),
  mean_data = mean(PA_TOTAL_SHORT,na.rm = TRUE),
  n_miss = sum(is.na(PA_TOTAL_SHORT)),
  median_data = median(PA_TOTAL_SHORT, na.rm = TRUE)
)  # This code uses summarise() to calculate specific statistics: number of unique values (n_distinct), mean, median, and total number of missing entries. Missing values are excluded (na.rm = TRUE) from mean and median calculations.
```
This data summary includes unique values (n_distinct = 3421), mean (mean_data = 2574.089), missing values (n_miss = 6763), and median (median_data = 1782).

# **Mean Imputation**

```{r}
data_shadow$pa_not_imputed <- data_shadow$PA_TOTAL_SHORT  # Adding a column called pa_not_imputed to maintain pa_total values after imputation

data_shadow <- impute_mean_at(data_shadow, .vars = vars(PA_TOTAL_SHORT))  # This code uses the impute_mean_at() function to fill in missing values in the PA_TOTAL_SHORT variable with its mean value. It applies the imputation to the data_shadow dataset, which includes shadow columns tracking missingness. This is a simple, fast method suitable when data is assumed to be Missing Completely At Random (MCAR).


data_shadow %>% 
  head()
```
This displays the first six(6) rows of the mean imputed physical activity total. 


## Visualizing Density Plots

```{r}
density_mean_imp <- ggplot(data_shadow) +
                geom_density(aes(pa_not_imputed, colour= "pa_not_imputed")) +
                geom_density(aes(PA_TOTAL_SHORT, colour= "PA_TOTAL_SHORT"))
plot(density_mean_imp)  # This ggplot2 code creates a density plot to compare the distribution of the original (non-imputed) PA_TOTAL_SHORT values (pa_not_imputed) with the mean-imputed values in PA_TOTAL_SHORT. Different colors are used to distinguish the two distributions, providing a visual comparison of their shapes.
```
It can be seen that the mean imputed has an increased peak  around 2500 minutes compared to the distribution of the not imputed variable. This shows that  the mean imputation has possibly inflated the mean compared to the sample distribution.

## Descriptive comparison of imputed and non imputed dataset

```{r}
median_pa_not_imputed <- median(data_shadow$pa_not_imputed,na.rm = TRUE)

median_pa_not_imputed


median_pa_imputed <- median(data_shadow$PA_TOTAL_SHORT) # "NA" has been removed so need not to add na.rm
median_pa_imputed


```

It can be observed that the median for non imputed pa short column  is 1782 and increased to 2379 after mean imputation. 


## Boxplot of PA_TOTAL_SHORT before mean_imputation

The code below is to measure side by side the distribution of the variables after and before imputation using a boxplot. 

```{r}
Non_imputed_pa <- ggplot(data_shadow, aes(x  = pa_not_imputed)) +
         geom_boxplot(outlier.shape = NA) +  # Avoid extreme outliers hiding the boxplot
         labs(title = " Total Physical Activity Before Mean Imputation",
              subtitle = "Median around 1700 ",
              y = "Total Physical Activity")+
         coord_flip()+
         theme_minimal()
```

## Boxplot of PA_TOTAL_SHORT after mean_imputation

```{r, warning=FALSE}

imputed_pa <- ggplot(data_shadow, aes(x  = PA_TOTAL_SHORT)) +
  geom_boxplot(outlier.shape = NA) +  # Avoid extreme outliers hiding the boxplot
  labs(title = " Total Physical Activity after Mean Imputation",
       subtitle = "Median around 2500 ",
       y = "Total Physical Activity") +
  coord_flip()+
  theme_minimal()

```

## Boxplot comparing non_imputed and imputed variable statistics 

```{r}
plot_grid(Non_imputed_pa, imputed_pa)
```
We can see the median for the non imputed variable is around 1700, The median value from the imputed  graph can not be determined explicitly with full certainty however, it is probably around  2500. Mean imputation can bias estimate from these observations. 


# **MICE Imputation**

Numeric Variables are Imputed using Predictive Mean Matching (PMM) by default. This involves building a linear regression model on complete cases, predicting values for missing cases, and then drawing imputed values from observed cases with similar predicted values.

Binary Categorical Variable (DIS_ASTHMA, DIS_DIAB) are Imputed using Logistic Regression. This involves building a logistic regression model to predict the probability of belonging to one of the two categories based on the other complete variables. The imputed value is then drawn based on this predicted probability.

mice will automatically apply PMM to the numeric variables and logistic regression to the binary categorical variable by default

```{r}

data_mice <- mice(health_data, m = 5, maxit = 5) # imputing missing data for each variable in the dataset using MICE with 5  imputed datasets , and 5 control iterations.

data_mice_complete <- complete(data_mice, action = "long")

data_mice_complete %>% 
  head() # Displaying first six(6) rows of the MICE imputed dataset

data_mice_complete %>% 
  tail() # Displaying last six(6) rows of the MICE imputed dataset

data_mice$method
```


## Renaming of data_mice variables 


I want to join the variables in data_mice_complete with health_data. However, they have the same columns name which may be confusing, so I want to rename the data_mice_complete variable. 

```{r}
data_mice_complete <- data_mice_complete %>% 
  rename(HS_GEN_HEALTH_imp = HS_GEN_HEALTH,
         NUT_VEG_QTY_imp = NUT_VEG_QTY,
         NUT_FRUITS_QTY_imp = NUT_FRUITS_QTY,
         PA_TOTAL_SHORT_imp = PA_TOTAL_SHORT,
         DIS_ASTHMA_EVER_imp = DIS_ASTHMA_EVER,
         DIS_DIAB_EVER_imp = DIS_DIAB_EVER)

data_mice_complete %>% 
  head()
```


## Joining the two datasets 

```{r}

health_data_c <- full_join( health_data, data_mice_complete, by = join_by("ID"))   # This code merges the original dataset health_data with a mice-imputed dataset data_mice_complete using a full join on the ID column. The resulting health_data_c contains both the original and imputed values, allowing side-by-side comparison of variables before and after imputation.

health_data_c %>% 
  head()

```

The data_mice has been full join to the health_data to a common variable - health_data_c. This is to allow for comparison of imputed and not imputed variables 

## Data Visualization 

### Density plot of PA_TOTAL_SHORT

```{r}
summary(health_data_c$PA_TOTAL_SHORT)
summary(health_data_c$PA_TOTAL_SHORT_imp)

density_imp <- ggplot(health_data_c) +
                geom_density(aes(PA_TOTAL_SHORT, colour= "PA_TOTAL_SHORT")) +
                geom_density(aes(PA_TOTAL_SHORT_imp, colour= "PA_TOTAL_SHORT_imp"))
plot(density_imp)

```

A similar distribution can be seen for Pa-total imputed and pa_total_not imputed. 


###  Density plot of PA_TOTAL_SHORT by .imp

```{r}
density_m_5 <- health_data_c %>% 
  mutate(.imp = as.factor(.imp)) %>%   # Converting .imp to a factor 
  ggplot(aes(x = PA_TOTAL_SHORT_imp, colour = .imp)) +
                geom_density()
plot(density_m_5)
```
A similar distribution was seen for each imputation made using MICE. 


The two main dataset that I am using are the health_data which contains missing data and data_mice_complete  which contains imputed values.Now this datasets have been joined to health_data_c. 

Let me summarize all the datasets before I proceed.

## Descriptive summary of Dataset before and after MICE imputation


### Summary of dataset befoe MICE imputation

```{r}

health_data %>% 
  summary()

```

we can see NA's across each variable. This shows missing  data point(s) is not imputed. 


### Summary of Dataset after MICE Imputation 

```{r}
health_data_imputed <- miss_var_summary(data_mice_complete)
health_data_imputed

data_mice_complete %>% 
  summary()


```

It can be seen that there is no missing data in the health_imputed dataset. This means the data points were correctly imputed using MICE.


### Boxplot of PA_TOTAL_SHORT before MICE_imputation

```{r}

plot_before_mice <- health_data %>% 
  ggplot(aes(PA_TOTAL_SHORT))+
  geom_boxplot()+
  labs(title = "Boxplot of Total physcial activity before MICE imputation",
       subtitle = "Median can be seen around around 1700")+
  coord_flip()  # This code creates a horizontal boxplot of PA_TOTAL_SHORT values from the original health_data dataset before MICE imputation. It uses geom_boxplot() to visualize the distribution, central tendency (median), and potential outliers. The plot includes a descriptive title and subtitle.

```



### Boxplot of PA_TOTAL_SHORT after MICE_imputation

```{r}
plot_after_mice <- pa_short_plot <- data_mice_complete %>% 
  ggplot(aes(PA_TOTAL_SHORT_imp))+
  geom_boxplot()+
  labs(title = "Boxplot of Total physcial activity after MICE imputation",
       subtitle = "Median can be seen around around 1700")+
  coord_flip() # This code creates a horizontal boxplot of PA_TOTAL_SHORT values from the original health_data dataset after MICE imputation. It uses geom_boxplot() to visualize the distribution, central tendency (median), and potential outliers. The plot includes a descriptive title and subtitle.

```
```{r}
plot_grid(plot_before_mice, plot_after_mice)
```


We can see the median value for physical activity before and after mice imputation are close ~ 1700. Comparing to mean_imputation( which had a median of ~ 2500). we can say mean_imputation can over or in other situations underestimate a sample parameter. 


# **Using KNN Methods**

## Overview of Dataset without imputed missing values

```{r}
health_data %>% 
  head() # displaying the first six(6) rows in the raw dataset(non imputed)

health_data %>% 
  summarise_all(~sum(is.na(.)))  # Displaying missing values in each column 

```


## KNN Imputation using "VIM"
 
```{r}

knn_imputed <- VIM::kNN(health_data, k = 3) # This code applies K-Nearest Neighbors (KNN) imputation using the VIM::kNN() function to fill missing values in the health_data dataset, using k=3 nearest neighbors. The method replaces missing entries with values from the most similar observations based on other variable patterns. The result, knn_imputed, contains both imputed values and indicators of where imputation occurred.

knn_imputed %>% 
  head()

```


### Summary of Dataset after KNN Imputation

```{r}
knn_imputed %>% 
  summary() # This displays the summary of the variables after KNN imputation using K = 3 neighbors. 

```

The various parameters in the summary table has been explained at the end of this script, for now I want to focus on how it affected the median of pa_total compared to the non_imputed pa_total variable.

### Boxplot of PA_TOTAL_SHORT before KNN_imputation

```{r}

pa_short_plot <- health_data %>% 
  ggplot(aes(PA_TOTAL_SHORT))+
  geom_boxplot()+
  labs(title = "Boxplot of Total physcial activity before KNN imputation",
       subtitle = "Median can be seen around around 1700")+
  coord_flip()  # This code creates a horizontal boxplot of PA_TOTAL_SHORT from the original health_data before applying KNN imputation. It uses geom_boxplot() to visualize the dataâ€™s spread, central tendency (median), and potential outliers, with a clear title and subtitle for interpretation.

```


### Boxplot of PA_TOTAL_SHORT after KNN _imputation

```{r}
pa_short_plot_knn <-ggplot(knn_imputed, aes(PA_TOTAL_SHORT))+
  geom_boxplot()+
  coord_flip()+
  labs(title = "Boxplot of PA_TOTAL_SHORT after KNN Imputation using VIM", 
       subtitle = "Median value around 1700 min") # This code creates a horizontal boxplot of PA_TOTAL_SHORT from the original health_data afterapplying KNN imputation. It uses geom_boxplot() to visualize the dataâ€™s spread, central tendency (median), and potential outliers, with a clear title and subtitle for interpretation.
```


### BOxplot of Pa_total_short comparison

```{r}
plot_grid(pa_short_plot,pa_short_plot_knn)
```

It can be observed that the distribution of the variable mean did not change significantly after KNN Imputation 

# **Regression Model**

I want to use simple regression to further show or display how the various types of data imputation method used in this porject affects or bias an association. 

I will build 4 regression models for:
1. the raw dataset with missing values,
2. the mean imputed dataset 
3. the MICE imputed dataset 
4. KNN dataset

## Regression model using non_imputed dataset 

```{r}
pa_fruit_model <- lm (PA_TOTAL_SHORT ~ NUT_FRUITS_QTY, data = health_data )  # This code fits a simple linear regression model using lm() to predict PA_TOTAL_SHORT (total physical activity) based on NUT_FRUITS_QTY (daily fruit intake). 

pa_fruit_model %>% 
  summary()  # The summary() function outputs model coefficients, R-squared, and statistical significance for the relationship.
```
We can see that the model with missing data showed a significant association between fruit quantity and physical activity total with a pvalue less than 0.001. A unit increase in fruit quantity, increases physical activity by 193.79 minutes. 

## Regression model using mean imputed dataset 

```{r}
pa_fruit_model <- lm (PA_TOTAL_SHORT ~ NUT_FRUITS_QTY, data = data_shadow ) # This code fits a linear regression model on the mean_imputed dataset from fruit intake (NUT_FRUITS_QTY).

pa_fruit_model %>% 
  summary()
```

We can see that with a unit increase in NUT_FRUITS_QTY, Physical activity increases by 159.5 minutes which is statistically significant(p_value<0.001)


## Regression model using MICE Imputed dataset

```{r}
set.seed(123)

pa_fruits_model <- lm(PA_TOTAL_SHORT_imp ~ NUT_FRUITS_QTY_imp, data = data_mice_complete) #Linear Regression model  using dataset with  mice imputations
summary(pa_fruits_model)


pa_fruits_miss <- data_mice_complete %>% with(lm(PA_TOTAL_SHORT_imp ~ NUT_FRUITS_QTY_imp)) # Pooled Regression 
summary(pa_fruits_miss)
```

We can see from the pooled estimate that with a unit increase in NUT_FRUITS_QTY, Physical activity increases by 195 minutes which is statistically significant(p_value<0.001). 

## Regression model using KNN Imputed dataset

```{r}

set.seed(123)

pa_asthma_model <- lm(PA_TOTAL_SHORT ~ NUT_FRUITS_QTY, data = knn_imputed) #Linear Regression model  using dataset with KNN imputations
summary(pa_asthma_model)


pa_asthma_miss <- knn_imputed %>% with(lm(PA_TOTAL_SHORT ~ NUT_FRUITS_QTY)) # Pooled Regression 
summary(pa_asthma_miss)
```


# **Summary of findings**

## Table of Median Values accross imputation methods

```{r}
library(knitr)

# Create a data frame for the medians of the various imputed datasets 
median_table <- data.frame(
  Imputation_Method = c("Not Imputed", "Mean Imputed", "MICE Imputed", "KNN Imputed"),
  Median_Value = c(1782, 2379, 1798, 1812)
)

median_table
```

We can see the median value is between 1700 and around 1800 for Not imputed, MICE and KNN imputed physical activity. However, the median for the mean imputed physical activity column is 2379, which is an "outlier"

## Regression model of PA_TOTAL_SHORT and NUT_FRUITS_QTY

```{r}

regression_table <- data.frame(
  Imputation_Method = c("Not Imputed", "Mean Imputed", "MICE Imputed", "KNN Imputed"),
  Intercept_B = c(2181, 2249, 2181, 2129),
  Coefficient_NUT_FRUITS_QTY = c(193.79, 159, 190, 179),
  P_Value = c("<2e-16", "<2e-16", "<2e-16", "<2e-16")
) # This code creates a summary data frame named regression_table comparing the results of four linear regression models predicting PA_TOTAL_SHORT using NUT_FRUITS_QTY, each based on a different imputation method. The table includes the intercept, coefficient for fruit intake, and the associated p-values.

regression_table

```

A significant relationship was observed between fruit consumption and total minutes of physical activity across all models (p < 0.002). However, the mean-imputed regression model revealed a rather minor increase in physical activity minutes (159) per unit increase in fruit consumption.

This may imply that mean imputation  underestimated the true effect of association between the predictor and an outcome 

It can also be shown that the intercepts and coefficients of the Not Imputed, MICE, and KNN imputed methods are identical. This could be because the percentage of missing data in the dataset is insufficient to skew the estimates. However, a considerable difference may be noticed between imputed and non imputed models if the proportion of data loss is high. 














